{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "49cfd5b6",
      "metadata": {
        "id": "49cfd5b6"
      },
      "source": [
        "# Stemming in NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6b98e81",
      "metadata": {
        "id": "f6b98e81"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "#nltk.download('punkt')  # Download the required resource (tokenizer models)\n",
        "#!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6a5b84c",
      "metadata": {
        "id": "d6a5b84c"
      },
      "outputs": [],
      "source": [
        "word = ['change','changing','changes','changed']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "622902d5",
      "metadata": {
        "id": "622902d5",
        "outputId": "f74e9560-f624-41c0-8c7d-e2f4b31ecbed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['change', 'changing', 'changes', 'changed']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53806986",
      "metadata": {
        "id": "53806986"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f56cb8d",
      "metadata": {
        "id": "2f56cb8d"
      },
      "outputs": [],
      "source": [
        "p = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5be1b987",
      "metadata": {
        "id": "5be1b987",
        "outputId": "88896e02-0e74-4597-f8ec-69f187dc6704"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chang\n",
            "chang\n",
            "chang\n",
            "chang\n"
          ]
        }
      ],
      "source": [
        "for w in word:\n",
        "    print(p.stem(w))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd2eed15",
      "metadata": {
        "id": "bd2eed15",
        "outputId": "05db1b7f-5387-4aab-d211-ac5694074c81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "change chang\n",
            "changing chang\n",
            "changes chang\n",
            "changed chang\n"
          ]
        }
      ],
      "source": [
        "for w in word:\n",
        "    print(w , p.stem(w))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e1eb61e",
      "metadata": {
        "id": "1e1eb61e"
      },
      "outputs": [],
      "source": [
        "sen = 'I want to change the world if world changed my career by changing abcd'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad049b2c",
      "metadata": {
        "id": "ad049b2c"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4891a15f",
      "metadata": {
        "id": "4891a15f"
      },
      "outputs": [],
      "source": [
        "toke = word_tokenize(sen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31e33432",
      "metadata": {
        "id": "31e33432",
        "outputId": "aadfd8b8-5a7b-418c-fb87-3a0e3a108e32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['I',\n",
              " 'want',\n",
              " 'to',\n",
              " 'change',\n",
              " 'the',\n",
              " 'world',\n",
              " 'if',\n",
              " 'world',\n",
              " 'changed',\n",
              " 'my',\n",
              " 'career',\n",
              " 'by',\n",
              " 'changing',\n",
              " 'abcd']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "toke"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18559d9d",
      "metadata": {
        "id": "18559d9d"
      },
      "outputs": [],
      "source": [
        "#sen.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e9e000f",
      "metadata": {
        "id": "6e9e000f",
        "outputId": "2bb91862-aabf-44c4-db9e-6e6b58c42692"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I i\n",
            "want want\n",
            "to to\n",
            "change chang\n",
            "the the\n",
            "world world\n",
            "if if\n",
            "world world\n",
            "changed chang\n",
            "my my\n",
            "career career\n",
            "by by\n",
            "changing chang\n",
            "abcd abcd\n"
          ]
        }
      ],
      "source": [
        "for w in toke:\n",
        "    print(w , p.stem(w))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be84d54b",
      "metadata": {
        "id": "be84d54b"
      },
      "outputs": [],
      "source": [
        "#nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "347deea7",
      "metadata": {
        "id": "347deea7"
      },
      "outputs": [],
      "source": [
        "#nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca13a690",
      "metadata": {
        "id": "ca13a690"
      },
      "source": [
        "# Lemmatization in NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35256907",
      "metadata": {
        "id": "35256907"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83e06afa",
      "metadata": {
        "id": "83e06afa"
      },
      "outputs": [],
      "source": [
        "le = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86b11cd1",
      "metadata": {
        "id": "86b11cd1",
        "outputId": "5d4a6acb-1777-4b82-b0c1-d7532ce4707b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['I',\n",
              " 'want',\n",
              " 'to',\n",
              " 'change',\n",
              " 'the',\n",
              " 'world',\n",
              " 'if',\n",
              " 'world',\n",
              " 'changed',\n",
              " 'my',\n",
              " 'career',\n",
              " 'by',\n",
              " 'changing',\n",
              " 'abcd']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "toke"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cd80d63",
      "metadata": {
        "id": "6cd80d63",
        "outputId": "0cb852f9-7568-4722-a28e-31b587d2deef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I I\n",
            "want want\n",
            "to to\n",
            "change change\n",
            "the the\n",
            "world world\n",
            "if if\n",
            "world world\n",
            "changed changed\n",
            "my my\n",
            "career career\n",
            "by by\n",
            "changing changing\n",
            "abcd abcd\n"
          ]
        }
      ],
      "source": [
        "for w in toke:\n",
        "    print(w , le.lemmatize(w))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e6dda9f",
      "metadata": {
        "scrolled": true,
        "id": "7e6dda9f",
        "outputId": "553cec6a-f2f2-4351-a1af-27e278d371ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'change'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "le.lemmatize('changes')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "850ecd2a",
      "metadata": {
        "id": "850ecd2a"
      },
      "source": [
        "# Tokenization in NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35bc5e77",
      "metadata": {
        "id": "35bc5e77"
      },
      "source": [
        "In Python, there are several libraries and tools available for performing tokenization and other NLP tasks. Here are a few examples using popular libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0b22c7e",
      "metadata": {
        "id": "c0b22c7e"
      },
      "source": [
        "# NLTK"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f6ecf14",
      "metadata": {
        "id": "2f6ecf14"
      },
      "source": [
        "NLTK (Natural Language Toolkit) is a widely used library for NLP tasks. To perform tokenization using NLTK, you need to install it first. You can do so by running pip install nltk. Here's an example of tokenizing a sentence using NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c0265a3",
      "metadata": {
        "id": "2c0265a3",
        "outputId": "f2c319e0-5863-4bb7-8f06-9126868f8bce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['I', \"'m\", 'from', 'aiQuest', 'Intelligence', '.', 'I', 'am', 'learning', 'NLP', '.', 'It', 'is', 'fascinating', '!']\n",
            "[\"I'm from aiQuest Intelligence.\", 'I am learning NLP.', 'It is fascinating!']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "sentence = \"I'm from aiQuest Intelligence. I am learning NLP. It is fascinating!\"\n",
        "word_tokens = word_tokenize(sentence)\n",
        "sentence_tokens = sent_tokenize(sentence)\n",
        "\n",
        "print(word_tokens)\n",
        "print(sentence_tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3707c60",
      "metadata": {
        "id": "a3707c60"
      },
      "source": [
        "# spaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1c406d7",
      "metadata": {
        "id": "f1c406d7"
      },
      "source": [
        "spaCy is another powerful library for NLP. To install spaCy, you can run pip install spacy and then download the appropriate language model. Here's an example of tokenization using spaCy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b17526b8",
      "metadata": {
        "id": "b17526b8"
      },
      "outputs": [],
      "source": [
        "#!pip install spacy\n",
        "# python -m spacy download en_core_web_sm    -> install in conda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42130eca",
      "metadata": {
        "id": "42130eca",
        "outputId": "02ce9690-4e95-4929-e61f-a26ad4769076"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['I', \"'m\", 'from', 'aiQuest', 'Intelligence', '.', 'I', 'am', 'learning', 'NLP', '.', 'It', 'is', 'fascinating', '!']\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')  # Load the English language model\n",
        "\n",
        "sentence = \"I'm from aiQuest Intelligence. I am learning NLP. It is fascinating!\"\n",
        "doc = nlp(sentence)\n",
        "\n",
        "word_tokens = [token.text for token in doc]\n",
        "\n",
        "print(word_tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ae4db8d",
      "metadata": {
        "id": "6ae4db8d"
      },
      "source": [
        "# Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a7932f5",
      "metadata": {
        "id": "0a7932f5"
      },
      "source": [
        "Transformers is a library built by Hugging Face that provides state-of-the-art pre-trained models for NLP. It offers various functionalities, including tokenization. To install Transformers, run pip install transformers. Here's an example of tokenization using Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef052805",
      "metadata": {
        "id": "ef052805",
        "outputId": "cb19701a-472a-4e60-e43b-eb2e6589e535"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['i', \"'\", 'm', 'from', 'ai', '##quest', 'intelligence', '.', 'i', 'am', 'learning', 'nl', '##p', '.', 'it', 'is', 'fascinating', '!']\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "sentence = \"I'm from aiQuest Intelligence. I am learning NLP. It is fascinating!\"\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "\n",
        "print(tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "351a12b3",
      "metadata": {
        "id": "351a12b3"
      },
      "source": [
        "# Named Entity Tokenization using NLTK"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3747ac00",
      "metadata": {
        "id": "3747ac00"
      },
      "source": [
        "To perform named entity tokenization using NLTK (Natural Language Toolkit), you can utilize the named entity recognition (NER) functionality provided by NLTK. Here's an example of how to extract named entity tokens from a sentence using NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "108ede5a",
      "metadata": {
        "id": "108ede5a",
        "outputId": "af158552-85dc-4b1c-812a-3ba297dfd0f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\rashe\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43e1d062",
      "metadata": {
        "id": "43e1d062",
        "outputId": "81663bad-0217-4caf-b6d7-b824786df10a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\rashe\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f061a0c5",
      "metadata": {
        "id": "f061a0c5",
        "outputId": "783a1101-d763-4ca9-bf94-3029b7347913"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['aiQuest Intelligence', 'NLP']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     C:\\Users\\rashe\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to\n",
            "[nltk_data]     C:\\Users\\rashe\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('maxent_ne_chunker')  # Download the required resource (NER models)\n",
        "nltk.download('words')  # Download the required resource (word corpus)\n",
        "\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "\n",
        "sentence = \"I'm from aiQuest Intelligence. I am learning NLP. It is fascinating!\"\n",
        "\n",
        "# Tokenize the sentence into words\n",
        "tokens = word_tokenize(sentence)\n",
        "\n",
        "# Perform part-of-speech tagging\n",
        "pos_tags = pos_tag(tokens)\n",
        "\n",
        "# Perform named entity recognition\n",
        "ner_tags = ne_chunk(pos_tags)\n",
        "\n",
        "# Extract named entity tokens\n",
        "named_entity_tokens = []\n",
        "\n",
        "for chunk in ner_tags:\n",
        "    if hasattr(chunk, 'label'): #hasattr(object, attribute)\n",
        "\n",
        "        named_entity_tokens.append(' '.join(c[0] for c in chunk))\n",
        "\n",
        "print(named_entity_tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffa3fd7a",
      "metadata": {
        "id": "ffa3fd7a"
      },
      "source": [
        "# Text Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "debf601e",
      "metadata": {
        "id": "debf601e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca4bfa72",
      "metadata": {
        "id": "ca4bfa72",
        "outputId": "f22639b6-d19f-41f5-f60b-005ad8f61089"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I love Bangladesh</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Could you give me an iphone?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hello how are you?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I want to talk you.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           test  class\n",
              "0             I love Bangladesh      1\n",
              "1  Could you give me an iphone?      0\n",
              "2            Hello how are you?      1\n",
              "3           I want to talk you.      1"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a25fbe5",
      "metadata": {
        "id": "4a25fbe5"
      },
      "source": [
        "# CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0a3791c",
      "metadata": {
        "id": "f0a3791c"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd44238e",
      "metadata": {
        "id": "dd44238e"
      },
      "outputs": [],
      "source": [
        "cv = CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "553a30d6",
      "metadata": {
        "id": "553a30d6",
        "outputId": "331735d8-9299-4dda-a6f0-de4e7966a1f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<4x14 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 16 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv_x = cv.fit_transform(df['test'])\n",
        "cv_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "431cff4c",
      "metadata": {
        "id": "431cff4c",
        "outputId": "4b946c3c-7372-4144-d4de-e4a2be83024c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1],\n",
              "       [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]], dtype=int64)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv_x.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a40be879",
      "metadata": {
        "id": "a40be879",
        "outputId": "b743554b-1116-4b45-eea7-413a352c7834"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\rashe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['an',\n",
              " 'are',\n",
              " 'bangladesh',\n",
              " 'could',\n",
              " 'give',\n",
              " 'hello',\n",
              " 'how',\n",
              " 'iphone',\n",
              " 'love',\n",
              " 'me',\n",
              " 'talk',\n",
              " 'to',\n",
              " 'want',\n",
              " 'you']"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv.get_feature_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "680ed45d",
      "metadata": {
        "id": "680ed45d"
      },
      "outputs": [],
      "source": [
        "cv_df = pd.DataFrame(cv_x.toarray(), columns=cv.get_feature_names(), index=df['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1c27935",
      "metadata": {
        "id": "d1c27935",
        "outputId": "c0487070-400a-42fa-c614-203498705d3f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>an</th>\n",
              "      <th>are</th>\n",
              "      <th>bangladesh</th>\n",
              "      <th>could</th>\n",
              "      <th>give</th>\n",
              "      <th>hello</th>\n",
              "      <th>how</th>\n",
              "      <th>iphone</th>\n",
              "      <th>love</th>\n",
              "      <th>me</th>\n",
              "      <th>talk</th>\n",
              "      <th>to</th>\n",
              "      <th>want</th>\n",
              "      <th>you</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>I love Bangladesh</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Could you give me an iphone?</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hello how are you?</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I want to talk you.</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              an  are  bangladesh  could  give  hello  how  \\\n",
              "test                                                                         \n",
              "I love Bangladesh              0    0           1      0     0      0    0   \n",
              "Could you give me an iphone?   1    0           0      1     1      0    0   \n",
              "Hello how are you?             0    1           0      0     0      1    1   \n",
              "I want to talk you.            0    0           0      0     0      0    0   \n",
              "\n",
              "                              iphone  love  me  talk  to  want  you  \n",
              "test                                                                 \n",
              "I love Bangladesh                  0     1   0     0   0     0    0  \n",
              "Could you give me an iphone?       1     0   1     0   0     0    1  \n",
              "Hello how are you?                 0     0   0     0   0     0    1  \n",
              "I want to talk you.                0     0   0     1   1     1    1  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "936b5265",
      "metadata": {
        "id": "936b5265",
        "outputId": "3b0f5345-de6f-496e-da2d-648d6bfabf6f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\rashe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "cv_df = pd.DataFrame(cv_x.toarray(), columns=cv.get_feature_names())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b2bae5b",
      "metadata": {
        "id": "2b2bae5b",
        "outputId": "8144d676-2dee-43f9-f4f2-f58b1ec19ce5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>an</th>\n",
              "      <th>are</th>\n",
              "      <th>bangladesh</th>\n",
              "      <th>could</th>\n",
              "      <th>give</th>\n",
              "      <th>hello</th>\n",
              "      <th>how</th>\n",
              "      <th>iphone</th>\n",
              "      <th>love</th>\n",
              "      <th>me</th>\n",
              "      <th>talk</th>\n",
              "      <th>to</th>\n",
              "      <th>want</th>\n",
              "      <th>you</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   an  are  bangladesh  could  give  hello  how  iphone  love  me  talk  to  \\\n",
              "0   0    0           1      0     0      0    0       0     1   0     0   0   \n",
              "1   1    0           0      1     1      0    0       1     0   1     0   0   \n",
              "2   0    1           0      0     0      1    1       0     0   0     0   0   \n",
              "3   0    0           0      0     0      0    0       0     0   0     1   1   \n",
              "\n",
              "   want  you  \n",
              "0     0    0  \n",
              "1     0    1  \n",
              "2     0    1  \n",
              "3     1    1  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acd5fd34",
      "metadata": {
        "id": "acd5fd34"
      },
      "source": [
        "# TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29a5e96e",
      "metadata": {
        "id": "29a5e96e"
      },
      "outputs": [],
      "source": [
        "tf = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "374ce011",
      "metadata": {
        "id": "374ce011"
      },
      "outputs": [],
      "source": [
        "tf_z = tf.fit_transform(df['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db374268",
      "metadata": {
        "id": "db374268",
        "outputId": "9dcf74b8-0b57-4502-8804-b916a31bb35b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<4x14 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 16 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32dc4e59",
      "metadata": {
        "id": "32dc4e59",
        "outputId": "c158a282-e300-4115-8ead-463a477328ef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\rashe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "cv_df = pd.DataFrame(tf_z.toarray(), columns=tf.get_feature_names(), index=df['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a0e7c7d",
      "metadata": {
        "id": "1a0e7c7d",
        "outputId": "a290ea7f-adb9-4f3c-ef6a-0f5306e04884"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>an</th>\n",
              "      <th>are</th>\n",
              "      <th>bangladesh</th>\n",
              "      <th>could</th>\n",
              "      <th>give</th>\n",
              "      <th>hello</th>\n",
              "      <th>how</th>\n",
              "      <th>iphone</th>\n",
              "      <th>love</th>\n",
              "      <th>me</th>\n",
              "      <th>talk</th>\n",
              "      <th>to</th>\n",
              "      <th>want</th>\n",
              "      <th>you</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>I love Bangladesh</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Could you give me an iphone?</th>\n",
              "      <td>0.430037</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.430037</td>\n",
              "      <td>0.430037</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.430037</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.430037</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.274487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hello how are you?</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.541736</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.541736</td>\n",
              "      <td>0.541736</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.345783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I want to talk you.</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.541736</td>\n",
              "      <td>0.541736</td>\n",
              "      <td>0.541736</td>\n",
              "      <td>0.345783</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    an       are  bangladesh     could  \\\n",
              "test                                                                     \n",
              "I love Bangladesh             0.000000  0.000000    0.707107  0.000000   \n",
              "Could you give me an iphone?  0.430037  0.000000    0.000000  0.430037   \n",
              "Hello how are you?            0.000000  0.541736    0.000000  0.000000   \n",
              "I want to talk you.           0.000000  0.000000    0.000000  0.000000   \n",
              "\n",
              "                                  give     hello       how    iphone  \\\n",
              "test                                                                   \n",
              "I love Bangladesh             0.000000  0.000000  0.000000  0.000000   \n",
              "Could you give me an iphone?  0.430037  0.000000  0.000000  0.430037   \n",
              "Hello how are you?            0.000000  0.541736  0.541736  0.000000   \n",
              "I want to talk you.           0.000000  0.000000  0.000000  0.000000   \n",
              "\n",
              "                                  love        me      talk        to  \\\n",
              "test                                                                   \n",
              "I love Bangladesh             0.707107  0.000000  0.000000  0.000000   \n",
              "Could you give me an iphone?  0.000000  0.430037  0.000000  0.000000   \n",
              "Hello how are you?            0.000000  0.000000  0.000000  0.000000   \n",
              "I want to talk you.           0.000000  0.000000  0.541736  0.541736   \n",
              "\n",
              "                                  want       you  \n",
              "test                                              \n",
              "I love Bangladesh             0.000000  0.000000  \n",
              "Could you give me an iphone?  0.000000  0.274487  \n",
              "Hello how are you?            0.000000  0.345783  \n",
              "I want to talk you.           0.541736  0.345783  "
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e69b187",
      "metadata": {
        "id": "1e69b187"
      },
      "source": [
        "# Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fb5a9cd",
      "metadata": {
        "id": "6fb5a9cd",
        "outputId": "84290cf9-d938-4738-fca5-63166adae3df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in c:\\users\\rashe\\anaconda3\\lib\\site-packages (4.1.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\rashe\\anaconda3\\lib\\site-packages (from gensim) (1.21.5)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\rashe\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\rashe\\anaconda3\\lib\\site-packages (from gensim) (1.10.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "327f605e",
      "metadata": {
        "id": "327f605e"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec, KeyedVectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1443e1cb",
      "metadata": {
        "id": "1443e1cb",
        "outputId": "08564955-ccc2-43fd-cd75-2c87ab735e5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['I', 'love', 'Bangladesh'],\n",
              " ['Could', 'you', 'give', 'me', 'an', 'iphone', '?'],\n",
              " ['Hello', 'how', 'are', 'you', '?'],\n",
              " ['I', 'want', 'to', 'talk', 'you', '.']]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_vector = [nltk.word_tokenize(test) for test in df['test']]\n",
        "text_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8daabe52",
      "metadata": {
        "id": "8daabe52"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(text_vector, min_count=1) #shift+tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a97a89f",
      "metadata": {
        "id": "9a97a89f",
        "outputId": "b05f561d-9bbc-4e4f-d6a3-b667a5cd142b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('an', 0.1782679259777069),\n",
              " ('I', 0.16072483360767365),\n",
              " ('give', 0.10560771077871323),\n",
              " ('how', 0.09215972572565079),\n",
              " ('iphone', 0.04891003668308258),\n",
              " ('are', 0.02700834721326828),\n",
              " ('Could', 0.007729316595941782),\n",
              " ('you', -0.03771639242768288),\n",
              " ('.', -0.045522838830947876),\n",
              " ('talk', -0.04649210348725319)]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.wv.most_similar('want')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}